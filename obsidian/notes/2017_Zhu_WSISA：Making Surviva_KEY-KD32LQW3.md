# WSISA: Making Survival Prediction from Whole Slide Histopathological Images
> [!info]+ <center>Metadata</center>
> 
> |<div style="width: 5em">Key</div>|Value|
> |--:|:--|
> |æ–‡çŒ®ç±»å‹|conferencePaper|
> |æ ‡é¢˜|WSISA: Making Survival Prediction from Whole Slide Histopathological Images|
> |çŸ­æ ‡é¢˜|WSISA|
> |ä½œè€…|[[Xinliang Zhu]]ã€ [[Jiawen Yao]]ã€ [[Feiyun Zhu]]ã€ [[Junzhou Huang]]|
> |DOI|[10.1109/CVPR.2017.725](https://doi.org/10.1109/CVPR.2017.725)|
> |å­˜æ¡£ä½ç½®||
> |é¦†è—ç›®å½•||
> |ç´¢ä¹¦å·||
> |ç‰ˆæƒ||
> |åˆ†ç±»|[[202204, 202206, 00_Histology]]|
> |ä¼šè®®åç§°|2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)|
> |åœ°ç‚¹||
> |æ¡ç›®é“¾æ¥|[My Library](zotero://select/library/items/KD32LQW3)|
> |PDF é™„ä»¶|[IEEE Xplore Full Text PDF](zotero://open-pdf/library/items/VH5HCI6M)|
> |å…³è”æ–‡çŒ®||
> ^Metadata


> [!example]- <center>æœ¬æ–‡æ ‡ç­¾</center>
> 
> `$=dv.current().file.tags`


> [!quote]- <center>Abstract</center>
> 
> Image-based precision medicine techniques can be used to better treat cancer patients. However, the gigapixel resolution of Whole Slide Histopathological Images (WSIs) makes traditional survival models computationally impossible. These models usually adopt manually labeled discriminative patches from region of interests (ROIs) and are unable to directly learn discriminative patches from WSIs. We argue that only a small set of patches cannot fully represent the patients survival status due to the heterogeneity of tumor. Another challenge is that survival prediction usually comes with insufficient training patient samples. In this paper, we propose an effective Whole Slide Histopathological Images Survival Analysis framework (WSISA) to overcome above challenges. To exploit survival-discriminative patterns from WSIs, we first extract hundreds of patches from each WSI by adaptive sampling and then group these images into different clusters. Then we propose to train an aggregation model to make patient-level predictions based on cluster-level Deep Convolutional Survival (DeepConvSurv) prediction results. Different from existing state-of-the-arts image-based survival models which extract features using some patches from small regions of WSIs, the proposed framework can efficiently exploit and utilize all discriminative patterns in WSIs to predict patients survival status. To the best of our knowledge, this has not been shown before. We apply our method to the survival predictions of glioma and non-small-cell lung cancer using three datasets. Results demonstrate the proposed framework can significantly improve the prediction performance compared with the existing state-of-the-arts survival methods.


> [!tldr]- <center>éšè—ä¿¡æ¯</center>
> 
> itemType:: conferencePaper
> title:: WSISA: Making Survival Prediction from Whole Slide Histopathological Images
> shortTitle:: WSISA
> creators:: [[Xinliang Zhu]]ã€ [[Jiawen Yao]]ã€ [[Feiyun Zhu]]ã€ [[Junzhou Huang]]
> proceedingsTitle:: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
> conferenceName:: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
> place:: 
> publisher:: 
> issue:: 
> pages:: 6855-6863
> language:: 
> DOI:: [10.1109/CVPR.2017.725](https://doi.org/10.1109/CVPR.2017.725)
> ISBN:: 
> url:: []()
> archive:: 2022-07-25
> archiveLocation:: 
> libraryCatalog:: 
> callNumber:: 
> rights:: 
> extra:: ğŸ·ï¸ _é¡¶ä¼šã€_readã€/Doneã€Cancerã€Computational modelingã€Feature extractionã€Lungsã€Trainingã€Tumors
> collection:: [[202204, 202206, 00_Histology]]
> tags:: #_é¡¶ä¼š #Done #Cancer #Computational_modeling #Feature_extraction #Lungs #Training #Tumors
> related:: 
> itemLink:: [My Library](zotero://select/library/items/KD32LQW3)
> pdfLink:: [IEEE Xplore Full Text PDF](zotero://open-pdf/library/items/VH5HCI6M)
> qnkey:: 2017_Zhu_WSISAï¼šMaking Surviva_KEY-KD32LQW3
> date:: 2017-07
> dateY:: 2017
> dateAdded:: 2022-04-19
> dateModified:: 2022-07-26
> year:: 2022
> dateCurrent:: 2022-07-27
> time:: 21:04:02
> week:: æ˜ŸæœŸä¸‰
> yearMonth:: 2022-07
> dateWeek:: 2022-07-27 æ˜ŸæœŸä¸‰
> dateTime:: 2022-07-27 21:04:02
> dateWeekTime:: 2022-07-27 21:04:02 æ˜ŸæœŸä¸‰
> 
> abstract:: Image-based precision medicine techniques can be used to better treat cancer patients. However, the gigapixel resolution of Whole Slide Histopathological Images (WSIs) makes traditional survival models computationally impossible. These models usually adopt manually labeled discriminative patches from region of interests (ROIs) and are unable to directly learn discriminative patches from WSIs. We argue that only a small set of patches cannot fully represent the patients survival status due to the heterogeneity of tumor. Another challenge is that survival prediction usually comes with insufficient training patient samples. In this paper, we propose an effective Whole Slide Histopathological Images Survival Analysis framework (WSISA) to overcome above challenges. To exploit survival-discriminative patterns from WSIs, we first extract hundreds of patches from each WSI by adaptive sampling and then group these images into different clusters. Then we propose to train an aggregation model to make patient-level predictions based on cluster-level Deep Convolutional Survival (DeepConvSurv) prediction results. Different from existing state-of-the-arts image-based survival models which extract features using some patches from small regions of WSIs, the proposed framework can efficiently exploit and utilize all discriminative patterns in WSIs to predict patients survival status. To the best of our knowledge, this has not been shown before. We apply our method to the survival predictions of glioma and non-small-cell lung cancer using three datasets. Results demonstrate the proposed framework can significantly improve the prediction performance compared with the existing state-of-the-arts survival methods.


ğŸ‘£â¿ğŸ‘£


## âœï¸ ç¬”è®°åŒº

>[!inbox]- <center>ğŸ“« ç¬”è®°ç®€æŠ¥</center>
>
> â° importDate:: 2022-07-27

> [!IMPORTANT]+ <center>ğŸŒ± ç ”è¯»å°è±¡</center>  
>
>ğŸ“Œ comment::  

> [!WARNING]+ <center>ğŸ£ æ€»ç»“</center>  
>
>ğŸ¯ ç ”ç©¶é—®é¢˜::  
ğŸ” ç ”ç©¶èƒŒæ™¯::  
ğŸš€ ç ”ç©¶æ–¹æ³•::  
ğŸ” ç ”ç©¶æ€è·¯::  
ğŸ“º ä¸»è¦å†…å®¹::  
ğŸ‰ ç ”ç©¶ç»“è®º::  
ğŸ—ï¸ åˆ›æ–°ç‚¹::  
ğŸ’© ç ”ç©¶å±€é™::  
ğŸ¾ ç ”ç©¶å±•æœ›::  
âœï¸ å¤‡æ³¨::  


ğŸ‘£â¿ğŸ‘£

## ğŸ“ æ³¨é‡Šç¬”è®° VH5HCI6M

> <span style="font-size: 15px;color: gray">ğŸ“ 2017-Zhu-WSISA: Making Survival Prediction from Whole Slide Histopathological Images</span>

^KEYrefTitle

> <span class="highlight" style="background-color: #ff666640">we train separate deep convolutional survival model (DeepConvSurv) on each cluster.</span> ([p6858](zotero://open-pdf/library/items/VH5HCI6M?page=6858&annotation=ATK3MHBL))

^KEYATK3MHBL

> <span class="highlight" style="background-color: #ff666640">By randomly sampling and setting a large enough sampling ratio</span>  
> å…³é”® ([p6859](zotero://open-pdf/library/items/VH5HCI6M?page=6859&annotation=NFZXYF89))

^KEYNFZXYF89







