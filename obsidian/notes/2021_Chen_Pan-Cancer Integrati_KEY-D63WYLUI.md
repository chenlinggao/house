# Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning
> [!info]+ <center>Metadata</center>
> 
> |<div style="width: 5em">Key</div>|Value|
> |--:|:--|
> |æ–‡çŒ®ç±»å‹|journalArticle|
> |æ ‡é¢˜|Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning|
> |çŸ­æ ‡é¢˜||
> |ä½œè€…|[[Richard J. Chen]]ã€ [[Ming Y. Lu]]ã€ [[Drew F. K. Williamson]]ã€ [[Tiffany Y. Chen]]ã€ [[Jana Lipkova]]ã€ [[Muhammad Shaban]]ã€ [[Maha Shady]]ã€ [[Mane Williams]]ã€ [[Bumjin Joo]]ã€ [[Zahra Noor]]ã€ [[Faisal Mahmood]]|
> |æœŸåˆŠåç§°|[[arXivï¼š2108.02278 [cs, q-bio]]]|
> |DOI|[](https://doi.org/)|
> |å­˜æ¡£ä½ç½®||
> |é¦†è—ç›®å½•||
> |ç´¢ä¹¦å·||
> |ç‰ˆæƒ||
> |åˆ†ç±»|[[202204, 00_Histology, MIL]]|
> |æ¡ç›®é“¾æ¥|[My Library](zotero://select/library/items/D63WYLUI)|
> |PDF é™„ä»¶|[arXiv Fulltext PDF](zotero://open-pdf/library/items/9SWBBIJ7)|
> |å…³è”æ–‡çŒ®|[[2020_Chen_Pathomic Fusionï¼šAn I_KEY-QAX5DKBD]]ã€ [[2020_Lu_Data Efficient and W_KEY-R8BCS375]]|
> ^Metadata


> [!example]- <center>æœ¬æ–‡æ ‡ç­¾</center>
> 
> `$=dv.current().file.tags`


> [!quote]- <center>Abstract</center>
> 
> The rapidly emerging field of deep learning-based computational pathology has demonstrated promise in developing objective prognostic models from histology whole slide images. However, most prognostic models are either based on histology or genomics alone and do not address how histology and genomics can be integrated to develop joint image-omic prognostic models. Additionally identifying explainable morphological and molecular descriptors from these models that govern such prognosis is of interest. We used multimodal deep learning to integrate gigapixel whole slide pathology images, RNA-seq abundance, copy number variation, and mutation data from 5,720 patients across 14 major cancer types. Our interpretable, weakly-supervised, multimodal deep learning algorithm is able to fuse these heterogeneous modalities for predicting outcomes and discover prognostic features from these modalities that corroborate with poor and favorable outcomes via multimodal interpretability. We compared our model with unimodal deep learning models trained on histology slides and molecular profiles alone, and demonstrate performance increase in risk stratification on 9 out of 14 cancers. In addition, we analyze morphologic and molecular markers responsible for prognostic predictions across all cancer types. All analyzed data, including morphological and molecular correlates of patient prognosis across the 14 cancer types at a disease and patient level are presented in an interactive open-access database (http://pancancer.mahmoodlab.org) to allow for further exploration and prognostic biomarker discovery. To validate that these model explanations are prognostic, we further analyzed high attention morphological regions in WSIs, which indicates that tumor-infiltrating lymphocyte presence corroborates with favorable cancer prognosis on 9 out of 14 cancer types studied.


> [!tldr]- <center>éšè—ä¿¡æ¯</center>
> 
> itemType:: journalArticle
> title:: Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning
> shortTitle:: 
> creators:: [[Richard J. Chen]]ã€ [[Ming Y. Lu]]ã€ [[Drew F. K. Williamson]]ã€ [[Tiffany Y. Chen]]ã€ [[Jana Lipkova]]ã€ [[Muhammad Shaban]]ã€ [[Maha Shady]]ã€ [[Mane Williams]]ã€ [[Bumjin Joo]]ã€ [[Zahra Noor]]ã€ [[Faisal Mahmood]]
> publicationTitle:: [[arXivï¼š2108.02278 [cs, q-bio]]]
> journalAbbreviation:: 
> volume:: 
> issue:: 
> pages:: 
> language:: 
> DOI:: [](https://doi.org/)
> ISSN:: 
> url:: [http://arxiv.org/abs/2108.02278](http://arxiv.org/abs/2108.02278)
> archive:: 2022-07-25
> archiveLocation:: 
> libraryCatalog:: 
> callNumber:: 
> rights:: 
> extra:: ğŸ·ï¸ _empahsisã€_readã€/Doneã€Computer Science - Artificial Intelligenceã€Computer Science - Computer Vision and Pattern Recognitionã€Quantitative Biology - Genomicsã€Quantitative Biology - Quantitative Methodsã€Quantitative Biology - Tissues and Organs
> collection:: [[202204, 00_Histology, MIL]]
> tags:: #_empahsis #Done #Computer_Science_-_Artificial_Intelligence #Computer_Science_-_Computer_Vision_and_Pattern_Recognition #Quantitative_Biology_-_Genomics #Quantitative_Biology_-_Quantitative_Methods #Quantitative_Biology_-_Tissues_and_Organs
> related:: [[2020_Chen_Pathomic Fusionï¼šAn I_KEY-QAX5DKBD]]ã€ [[2020_Lu_Data Efficient and W_KEY-R8BCS375]]
> itemLink:: [My Library](zotero://select/library/items/D63WYLUI)
> pdfLink:: [arXiv Fulltext PDF](zotero://open-pdf/library/items/9SWBBIJ7)
> qnkey:: 2021_Chen_Pan-Cancer Integrati_KEY-D63WYLUI
> date:: 2021-08-04
> dateY:: 2021
> dateAdded:: 2022-04-24
> dateModified:: 2022-07-26
> year:: 2022
> dateCurrent:: 2022-07-27
> time:: 21:04:07
> week:: æ˜ŸæœŸä¸‰
> yearMonth:: 2022-07
> dateWeek:: 2022-07-27 æ˜ŸæœŸä¸‰
> dateTime:: 2022-07-27 21:04:07
> dateWeekTime:: 2022-07-27 21:04:07 æ˜ŸæœŸä¸‰
> 
> abstract:: The rapidly emerging field of deep learning-based computational pathology has demonstrated promise in developing objective prognostic models from histology whole slide images. However, most prognostic models are either based on histology or genomics alone and do not address how histology and genomics can be integrated to develop joint image-omic prognostic models. Additionally identifying explainable morphological and molecular descriptors from these models that govern such prognosis is of interest. We used multimodal deep learning to integrate gigapixel whole slide pathology images, RNA-seq abundance, copy number variation, and mutation data from 5,720 patients across 14 major cancer types. Our interpretable, weakly-supervised, multimodal deep learning algorithm is able to fuse these heterogeneous modalities for predicting outcomes and discover prognostic features from these modalities that corroborate with poor and favorable outcomes via multimodal interpretability. We compared our model with unimodal deep learning models trained on histology slides and molecular profiles alone, and demonstrate performance increase in risk stratification on 9 out of 14 cancers. In addition, we analyze morphologic and molecular markers responsible for prognostic predictions across all cancer types. All analyzed data, including morphological and molecular correlates of patient prognosis across the 14 cancer types at a disease and patient level are presented in an interactive open-access database (httpï¼š//pancancer.mahmoodlab.org) to allow for further exploration and prognostic biomarker discovery. To validate that these model explanations are prognostic, we further analyzed high attention morphological regions in WSIs, which indicates that tumor-infiltrating lymphocyte presence corroborates with favorable cancer prognosis on 9 out of 14 cancer types studied.


ğŸ‘£â¿ğŸ‘£


## âœï¸ ç¬”è®°åŒº

>[!inbox]- <center>ğŸ“« ç¬”è®°ç®€æŠ¥</center>
>
> â° importDate:: 2022-07-27

> [!IMPORTANT]+ <center>ğŸŒ± ç ”è¯»å°è±¡</center>  
>
>ğŸ“Œ comment::  

> [!WARNING]+ <center>ğŸ£ æ€»ç»“</center>  
>
>ğŸ¯ ç ”ç©¶é—®é¢˜::  
ğŸ” ç ”ç©¶èƒŒæ™¯::  
ğŸš€ ç ”ç©¶æ–¹æ³•::  
ğŸ” ç ”ç©¶æ€è·¯::  
ğŸ“º ä¸»è¦å†…å®¹::  
ğŸ‰ ç ”ç©¶ç»“è®º::  
ğŸ—ï¸ åˆ›æ–°ç‚¹::  
ğŸ’© ç ”ç©¶å±€é™::  
ğŸ¾ ç ”ç©¶å±•æœ›::  
âœï¸ å¤‡æ³¨::  


ğŸ‘£â¿ğŸ‘£

## ğŸ“ æ³¨é‡Šç¬”è®° 9SWBBIJ7

> <span style="font-size: 15px;color: gray">ğŸ“ 2021-Chen-Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning</span>

^KEYrefTitle

> <span class="highlight" style="background-color: #ffd40040">whole slide pathology images</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=XKYY3LTM))

^KEYXKYY3LTM

> <span class="highlight" style="background-color: #ffd40040">RNA-seq abundance,</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=QYRCW2MS))

^KEYQYRCW2MS

> <span class="highlight" style="background-color: #ffd40040">copy number variation</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=4PPNWBUZ))

^KEY4PPNWBUZ

> <span class="highlight" style="background-color: #ff666640">weakly-supervised</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=YE9Y632D))

^KEYYE9Y632D

> <span class="highlight" style="background-color: #ff666640">Methods</span> ([p14](zotero://open-pdf/library/items/9SWBBIJ7?page=14&annotation=3PWJXGFK))

^KEY3PWJXGFK

> <span class="highlight" style="background-color: #ffd40040">To perform survival prediction from WSIs,</span> ([p14](zotero://open-pdf/library/items/9SWBBIJ7?page=14&annotation=B3HNCD4Z))

^KEYB3HNCD4Z

> <span class="highlight" style="background-color: #ff666640">Under the multiple instance learning framework, each gigapixel WSI is divided into smaller regions and viewed as a collection (known as a bag) of patches (known as instances) with a corresponding slide-level label used for training.</span> ([p14](zotero://open-pdf/library/items/9SWBBIJ7?page=14&annotation=FPVKQQ3L))

^KEYFPVKQQ3L

> <span class="highlight" style="background-color: #ff666640">for the ResNet50 encoder we used. Since survival outcome information is available at the patient-level instead of for individual slides, we collectively treat all WSIs corresponding to a patient case as a single WSI bag during training and evaluation. Namely, for a patient case with N WSIs with bag sizes M1, Â· Â· Â· , MN respectively, the WSI bag corresponding the patient is formed by concatenating all N bags, and has dimensions M Ã— 1024, where M = âˆ‘N i=1 Mi.</span> ([p15](zotero://open-pdf/library/items/9SWBBIJ7?page=15&annotation=TZMA6G2K))

^KEYTZMA6G2K

> <span class="highlight" style="background-color: #ffd40040">scaled exponential linear units (SeLU)</span> ([p15](zotero://open-pdf/library/items/9SWBBIJ7?page=15&annotation=3SDAMWG6))

^KEY3SDAMWG6

> <span class="highlight" style="background-color: #ffd40040">Alpha Dropout</span> ([p15](zotero://open-pdf/library/items/9SWBBIJ7?page=15&annotation=PDRD9RNM))

^KEYPDRD9RNM

> <span class="highlight" style="background-color: #ffd40040">Because WSIs across patient samples have varying image dimension sizes, we randomly sampled paired WSIs and molecular features with a mini-batch size of 1.</span> ([p17](zotero://open-pdf/library/items/9SWBBIJ7?page=17&annotation=HPB8MULG))

^KEYHPB8MULG







