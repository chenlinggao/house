# Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning
> [!info]+ <center>Metadata</center>
> 
> |<div style="width: 5em">Key</div>|Value|
> |--:|:--|
> |文献类型|journalArticle|
> |标题|Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning|
> |短标题||
> |作者|[[Richard J. Chen]]、 [[Ming Y. Lu]]、 [[Drew F. K. Williamson]]、 [[Tiffany Y. Chen]]、 [[Jana Lipkova]]、 [[Muhammad Shaban]]、 [[Maha Shady]]、 [[Mane Williams]]、 [[Bumjin Joo]]、 [[Zahra Noor]]、 [[Faisal Mahmood]]|
> |期刊名称|[[arXiv：2108.02278 [cs, q-bio]]]|
> |DOI|[](https://doi.org/)|
> |存档位置||
> |馆藏目录||
> |索书号||
> |版权||
> |分类|[[202204, 00_Histology, MIL]]|
> |条目链接|[My Library](zotero://select/library/items/D63WYLUI)|
> |PDF 附件|[arXiv Fulltext PDF](zotero://open-pdf/library/items/9SWBBIJ7)|
> |关联文献|[[2020_Chen_Pathomic Fusion：An I_KEY-QAX5DKBD]]、 [[2020_Lu_Data Efficient and W_KEY-R8BCS375]]|
> ^Metadata


> [!example]- <center>本文标签</center>
> 
> `$=dv.current().file.tags`


> [!quote]- <center>Abstract</center>
> 
> The rapidly emerging field of deep learning-based computational pathology has demonstrated promise in developing objective prognostic models from histology whole slide images. However, most prognostic models are either based on histology or genomics alone and do not address how histology and genomics can be integrated to develop joint image-omic prognostic models. Additionally identifying explainable morphological and molecular descriptors from these models that govern such prognosis is of interest. We used multimodal deep learning to integrate gigapixel whole slide pathology images, RNA-seq abundance, copy number variation, and mutation data from 5,720 patients across 14 major cancer types. Our interpretable, weakly-supervised, multimodal deep learning algorithm is able to fuse these heterogeneous modalities for predicting outcomes and discover prognostic features from these modalities that corroborate with poor and favorable outcomes via multimodal interpretability. We compared our model with unimodal deep learning models trained on histology slides and molecular profiles alone, and demonstrate performance increase in risk stratification on 9 out of 14 cancers. In addition, we analyze morphologic and molecular markers responsible for prognostic predictions across all cancer types. All analyzed data, including morphological and molecular correlates of patient prognosis across the 14 cancer types at a disease and patient level are presented in an interactive open-access database (http://pancancer.mahmoodlab.org) to allow for further exploration and prognostic biomarker discovery. To validate that these model explanations are prognostic, we further analyzed high attention morphological regions in WSIs, which indicates that tumor-infiltrating lymphocyte presence corroborates with favorable cancer prognosis on 9 out of 14 cancer types studied.


> [!tldr]- <center>隐藏信息</center>
> 
> itemType:: journalArticle
> title:: Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning
> shortTitle:: 
> creators:: [[Richard J. Chen]]、 [[Ming Y. Lu]]、 [[Drew F. K. Williamson]]、 [[Tiffany Y. Chen]]、 [[Jana Lipkova]]、 [[Muhammad Shaban]]、 [[Maha Shady]]、 [[Mane Williams]]、 [[Bumjin Joo]]、 [[Zahra Noor]]、 [[Faisal Mahmood]]
> publicationTitle:: [[arXiv：2108.02278 [cs, q-bio]]]
> journalAbbreviation:: 
> volume:: 
> issue:: 
> pages:: 
> language:: 
> DOI:: [](https://doi.org/)
> ISSN:: 
> url:: [http://arxiv.org/abs/2108.02278](http://arxiv.org/abs/2108.02278)
> archive:: 2022-07-25
> archiveLocation:: 
> libraryCatalog:: 
> callNumber:: 
> rights:: 
> extra:: 🏷️ _empahsis、_read、/Done、Computer Science - Artificial Intelligence、Computer Science - Computer Vision and Pattern Recognition、Quantitative Biology - Genomics、Quantitative Biology - Quantitative Methods、Quantitative Biology - Tissues and Organs
> collection:: [[202204, 00_Histology, MIL]]
> tags:: #_empahsis #Done #Computer_Science_-_Artificial_Intelligence #Computer_Science_-_Computer_Vision_and_Pattern_Recognition #Quantitative_Biology_-_Genomics #Quantitative_Biology_-_Quantitative_Methods #Quantitative_Biology_-_Tissues_and_Organs
> related:: [[2020_Chen_Pathomic Fusion：An I_KEY-QAX5DKBD]]、 [[2020_Lu_Data Efficient and W_KEY-R8BCS375]]
> itemLink:: [My Library](zotero://select/library/items/D63WYLUI)
> pdfLink:: [arXiv Fulltext PDF](zotero://open-pdf/library/items/9SWBBIJ7)
> qnkey:: 2021_Chen_Pan-Cancer Integrati_KEY-D63WYLUI
> date:: 2021-08-04
> dateY:: 2021
> dateAdded:: 2022-04-24
> dateModified:: 2022-07-26
> year:: 2022
> dateCurrent:: 2022-07-27
> time:: 21:04:07
> week:: 星期三
> yearMonth:: 2022-07
> dateWeek:: 2022-07-27 星期三
> dateTime:: 2022-07-27 21:04:07
> dateWeekTime:: 2022-07-27 21:04:07 星期三
> 
> abstract:: The rapidly emerging field of deep learning-based computational pathology has demonstrated promise in developing objective prognostic models from histology whole slide images. However, most prognostic models are either based on histology or genomics alone and do not address how histology and genomics can be integrated to develop joint image-omic prognostic models. Additionally identifying explainable morphological and molecular descriptors from these models that govern such prognosis is of interest. We used multimodal deep learning to integrate gigapixel whole slide pathology images, RNA-seq abundance, copy number variation, and mutation data from 5,720 patients across 14 major cancer types. Our interpretable, weakly-supervised, multimodal deep learning algorithm is able to fuse these heterogeneous modalities for predicting outcomes and discover prognostic features from these modalities that corroborate with poor and favorable outcomes via multimodal interpretability. We compared our model with unimodal deep learning models trained on histology slides and molecular profiles alone, and demonstrate performance increase in risk stratification on 9 out of 14 cancers. In addition, we analyze morphologic and molecular markers responsible for prognostic predictions across all cancer types. All analyzed data, including morphological and molecular correlates of patient prognosis across the 14 cancer types at a disease and patient level are presented in an interactive open-access database (http：//pancancer.mahmoodlab.org) to allow for further exploration and prognostic biomarker discovery. To validate that these model explanations are prognostic, we further analyzed high attention morphological regions in WSIs, which indicates that tumor-infiltrating lymphocyte presence corroborates with favorable cancer prognosis on 9 out of 14 cancer types studied.


👣➿👣


## ✏️ 笔记区

>[!inbox]- <center>📫 笔记简报</center>
>
> ⏰ importDate:: 2022-07-27

> [!IMPORTANT]+ <center>🌱 研读印象</center>  
>
>📌 comment::  

> [!WARNING]+ <center>🐣 总结</center>  
>
>🎯 研究问题::  
🔎 研究背景::  
🚀 研究方法::  
🐔 研究思路::  
📺 主要内容::  
🎉 研究结论::  
🗝️ 创新点::  
💩 研究局限::  
🐾 研究展望::  
✏️ 备注::  


👣➿👣

## 📝 注释笔记 9SWBBIJ7

> <span style="font-size: 15px;color: gray">📍 2021-Chen-Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning</span>

^KEYrefTitle

> <span class="highlight" style="background-color: #ffd40040">whole slide pathology images</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=XKYY3LTM))

^KEYXKYY3LTM

> <span class="highlight" style="background-color: #ffd40040">RNA-seq abundance,</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=QYRCW2MS))

^KEYQYRCW2MS

> <span class="highlight" style="background-color: #ffd40040">copy number variation</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=4PPNWBUZ))

^KEY4PPNWBUZ

> <span class="highlight" style="background-color: #ff666640">weakly-supervised</span> ([p2](zotero://open-pdf/library/items/9SWBBIJ7?page=2&annotation=YE9Y632D))

^KEYYE9Y632D

> <span class="highlight" style="background-color: #ff666640">Methods</span> ([p14](zotero://open-pdf/library/items/9SWBBIJ7?page=14&annotation=3PWJXGFK))

^KEY3PWJXGFK

> <span class="highlight" style="background-color: #ffd40040">To perform survival prediction from WSIs,</span> ([p14](zotero://open-pdf/library/items/9SWBBIJ7?page=14&annotation=B3HNCD4Z))

^KEYB3HNCD4Z

> <span class="highlight" style="background-color: #ff666640">Under the multiple instance learning framework, each gigapixel WSI is divided into smaller regions and viewed as a collection (known as a bag) of patches (known as instances) with a corresponding slide-level label used for training.</span> ([p14](zotero://open-pdf/library/items/9SWBBIJ7?page=14&annotation=FPVKQQ3L))

^KEYFPVKQQ3L

> <span class="highlight" style="background-color: #ff666640">for the ResNet50 encoder we used. Since survival outcome information is available at the patient-level instead of for individual slides, we collectively treat all WSIs corresponding to a patient case as a single WSI bag during training and evaluation. Namely, for a patient case with N WSIs with bag sizes M1, · · · , MN respectively, the WSI bag corresponding the patient is formed by concatenating all N bags, and has dimensions M × 1024, where M = ∑N i=1 Mi.</span> ([p15](zotero://open-pdf/library/items/9SWBBIJ7?page=15&annotation=TZMA6G2K))

^KEYTZMA6G2K

> <span class="highlight" style="background-color: #ffd40040">scaled exponential linear units (SeLU)</span> ([p15](zotero://open-pdf/library/items/9SWBBIJ7?page=15&annotation=3SDAMWG6))

^KEY3SDAMWG6

> <span class="highlight" style="background-color: #ffd40040">Alpha Dropout</span> ([p15](zotero://open-pdf/library/items/9SWBBIJ7?page=15&annotation=PDRD9RNM))

^KEYPDRD9RNM

> <span class="highlight" style="background-color: #ffd40040">Because WSIs across patient samples have varying image dimension sizes, we randomly sampled paired WSIs and molecular features with a mini-batch size of 1.</span> ([p17](zotero://open-pdf/library/items/9SWBBIJ7?page=17&annotation=HPB8MULG))

^KEYHPB8MULG







