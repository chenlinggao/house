# Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation
> [!info]+ <center>Metadata</center>
> 
> |<div style="width: 5em">Key</div>|Value|
> |--:|:--|
> |文献类型|conferencePaper|
> |标题|Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation|
> |短标题||
> |作者|[[Jinheng Xie]]、 [[Jianfeng Xiang]]、 [[Junliang Chen]]、 [[Xianxu Hou]]、 [[Xiaodong Zhao]]、 [[Linlin Shen]]|
> |DOI|[](https://doi.org/)|
> |存档位置||
> |馆藏目录||
> |索书号||
> |版权||
> |分类|[[00_Histology]]|
> |会议名称|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|
> |地点||
> |条目链接|[My Library](zotero://select/library/items/SXQ5HBNN)|
> |PDF 附件|[arXiv Fulltext PDF](zotero://open-pdf/library/items/VDK3A8LP)|
> |关联文献|[[2020_Zhang_Rethinking the Route_KEY-BENL3W8J]]、 [[2019_Wei_Unsupervised object _KEY-C2TT9LJW]]|
> ^Metadata


> [!example]- <center>本文标签</center>
> 
> `$=dv.current().file.tags`


> [!quote]- <center>Abstract</center>
> 
> While class activation map (CAM) generated by image classification network has been widely used for weakly supervised object localization (WSOL) and semantic segmentation (WSSS), such classifiers usually focus on discriminative object regions. In this paper, we propose Contrastive learning for Class-agnostic Activation Map (C$^2$AM) generation only using unlabeled image data, without the involvement of image-level supervision. The core idea comes from the observation that i) semantic information of foreground objects usually differs from their backgrounds; ii) foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space. We form the positive and negative pairs based on the above relations and force the network to disentangle foreground and background with a class-agnostic activation map using a novel contrastive loss. As the network is guided to discriminate cross-image foreground-background, the class-agnostic activation maps learned by our approach generate more complete object regions. We successfully extracted from C$^2$AM class-agnostic object bounding boxes for object localization and background cues to refine CAM generated by classification network for semantic segmentation. Extensive experiments on CUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and WSSS can benefit from the proposed C$^2$AM.


> [!tldr]- <center>隐藏信息</center>
> 
> itemType:: conferencePaper
> title:: Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation
> shortTitle:: 
> creators:: [[Jinheng Xie]]、 [[Jianfeng Xiang]]、 [[Junliang Chen]]、 [[Xianxu Hou]]、 [[Xiaodong Zhao]]、 [[Linlin Shen]]
> proceedingsTitle:: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
> conferenceName:: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
> place:: 
> publisher:: arXiv
> issue:: 
> pages:: 
> language:: 
> DOI:: [](https://doi.org/)
> ISBN:: 
> url:: [http://arxiv.org/abs/2203.13505](http://arxiv.org/abs/2203.13505)
> archive:: 2022-07-25
> archiveLocation:: 
> libraryCatalog:: 
> callNumber:: 
> rights:: 
> extra:: 🏷️ _empahsis、_read、Computer Science - Computer Vision and Pattern Recognition、对比学习
> collection:: [[00_Histology]]
> tags:: #_empahsis #Done #对比学习 #Computer_Science_-_Computer_Vision_and_Pattern_Recognition
> related:: [[2020_Zhang_Rethinking the Route_KEY-BENL3W8J]]、 [[2019_Wei_Unsupervised object _KEY-C2TT9LJW]]
> itemLink:: [My Library](zotero://select/library/items/SXQ5HBNN)
> pdfLink:: [arXiv Fulltext PDF](zotero://open-pdf/library/items/VDK3A8LP)
> qnkey:: 2022_Xie_Contrastive learning_KEY-SXQ5HBNN
> date:: 2022-03-25
> dateY:: 2022
> dateAdded:: 2022-06-08
> dateModified:: 2022-07-26
> year:: 2022
> dateCurrent:: 2022-08-01
> time:: 10:34:17
> week:: 星期一
> yearMonth:: 2022-08
> dateWeek:: 2022-08-01 星期一
> dateTime:: 2022-08-01 10:34:17
> dateWeekTime:: 2022-08-01 10:34:17 星期一
> 
> abstract:: While class activation map (CAM) generated by image classification network has been widely used for weakly supervised object localization (WSOL) and semantic segmentation (WSSS), such classifiers usually focus on discriminative object regions. In this paper, we propose Contrastive learning for Class-agnostic Activation Map (C$^2$AM) generation only using unlabeled image data, without the involvement of image-level supervision. The core idea comes from the observation that i) semantic information of foreground objects usually differs from their backgrounds; ii) foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space. We form the positive and negative pairs based on the above relations and force the network to disentangle foreground and background with a class-agnostic activation map using a novel contrastive loss. As the network is guided to discriminate cross-image foreground-background, the class-agnostic activation maps learned by our approach generate more complete object regions. We successfully extracted from C$^2$AM class-agnostic object bounding boxes for object localization and background cues to refine CAM generated by classification network for semantic segmentation. Extensive experiments on CUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and WSSS can benefit from the proposed C$^2$AM.


👣➿👣


## ✏️ 笔记区

>[!inbox]- <center>📫 笔记简报</center>
>
> ⏰ importDate:: 2022-07-27

> [!IMPORTANT]+ <center>🌱 研读印象</center>  
>
>📌 comment::  

> [!WARNING]+ <center>🐣 总结</center>  
>
>🎯 研究问题::  
🔎 研究背景::  
🚀 研究方法::  
🐔 研究思路::  
📺 主要内容::  
🎉 研究结论::  
🗝️ 创新点::  
💩 研究局限::  
🐾 研究展望::  
✏️ 备注::  


👣➿👣

## 📝 注释笔记 VDK3A8LP

> <span style="font-size: 15px;color: gray">📍 2022-Xie-Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation</span>

^KEYrefTitle

> <span class="highlight" style="background-color: #ffd40040">Contrastive learning for Class-agnostic Activation Map (C2AM)</span> ([p1](zotero://open-pdf/library/items/VDK3A8LP?page=1&annotation=MZ286SXN))

^KEYMZ286SXN

> <span class="highlight" style="background-color: #ffd40040">semantic information of foreground objects usually differs from their backgrounds</span> ([p1](zotero://open-pdf/library/items/VDK3A8LP?page=1&annotation=EIAU3L8P))

^KEYEIAU3L8P

> <span class="highlight" style="background-color: #ffd40040">foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space.</span> ([p1](zotero://open-pdf/library/items/VDK3A8LP?page=1&annotation=WDDE8ZBL))

^KEYWDDE8ZBL

> <span class="highlight" style="background-color: #ff666640">cross-image foreground-background contrast,</span> ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=UYPRKXVY))

^KEYUYPRKXVY

> <span class="image#ffd400">null</span>建立正负样本对，这里是通过一个解缠绕器来将feature map分成n个前景和n个背景，然后建立所有组合的正负样本对。 ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=WNEWH6GB))

^KEYWNEWH6GB

> <span class="highlight" style="background-color: #ff666640">The foreground-background representation pair, i.e., (vf i , vb j), is treated as the negative pair.</span> ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=2D4XTAEA))

^KEY2D4XTAEA

> <span class="highlight" style="background-color: #ffd40040">Positive pairs with large distances will affect the learning process, as there is fewer similar semantics in these two foreground objects or backgrounds.</span>  
> 这是一个问题 ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=P6QSBAAV))

^KEYP6QSBAAV

> <span class="image#ffd400">null</span>建立正样本对。因为同样的样本间有相似的特征空间，如果样本间特征空间的距离较远而它们又属于同一类，则会大大影响训练过程，所以需要衡量样本对之间的距离，并且通过排序的方法来赋予不同的权重。 ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=7JXF7HJR))

^KEY7JXF7HJR

> <span class="highlight" style="background-color: #ffd40040">How to determine foreground regions. As th same contrastive loss is applied to foreground-foreground and background-background positive pairs, it can not guarantee that foreground or background regions are activated in Pi. To solve this problem, we set a threshold to binarize the class-agnostic activation maps and detect the largest contour to determine the object regions.</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=5HEEVM8Q))

^KEY5HEEVM8Q

> <span class="highlight" style="background-color: #ff666640">Specifically, WSOL is divided into two tasks: classagnostic object localization and object classification.</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=XNLTQDGC))

^KEYXNLTQDGC

> <span class="highlight" style="background-color: #ffd40040">We set a threshold to binarize the classagnostic activation maps and then extract class-agnostic object bounding boxes as pseudo labels</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=8NB5XJZD))

^KEY8NB5XJZD

> <span class="highlight" style="background-color: #ff666640">Specifically, we use the background activation maps (1−P) as pseudo labels to further train a model to predict the background regions, i.e., background cues, in the image.</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=CMIZAGBW))

^KEYCMIZAGBW







