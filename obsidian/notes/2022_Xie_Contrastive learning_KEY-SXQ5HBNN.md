# Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation
> [!info]+ <center>Metadata</center>
> 
> |<div style="width: 5em">Key</div>|Value|
> |--:|:--|
> |æ–‡çŒ®ç±»å‹|conferencePaper|
> |æ ‡é¢˜|Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation|
> |çŸ­æ ‡é¢˜||
> |ä½œè€…|[[Jinheng Xie]]ã€ [[Jianfeng Xiang]]ã€ [[Junliang Chen]]ã€ [[Xianxu Hou]]ã€ [[Xiaodong Zhao]]ã€ [[Linlin Shen]]|
> |DOI|[](https://doi.org/)|
> |å­˜æ¡£ä½ç½®||
> |é¦†è—ç›®å½•||
> |ç´¢ä¹¦å·||
> |ç‰ˆæƒ||
> |åˆ†ç±»|[[00_Histology]]|
> |ä¼šè®®åç§°|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|
> |åœ°ç‚¹||
> |æ¡ç›®é“¾æ¥|[My Library](zotero://select/library/items/SXQ5HBNN)|
> |PDF é™„ä»¶|[arXiv Fulltext PDF](zotero://open-pdf/library/items/VDK3A8LP)|
> |å…³è”æ–‡çŒ®|[[2020_Zhang_Rethinking the Route_KEY-BENL3W8J]]ã€ [[2019_Wei_Unsupervised object _KEY-C2TT9LJW]]|
> ^Metadata


> [!example]- <center>æœ¬æ–‡æ ‡ç­¾</center>
> 
> `$=dv.current().file.tags`


> [!quote]- <center>Abstract</center>
> 
> While class activation map (CAM) generated by image classification network has been widely used for weakly supervised object localization (WSOL) and semantic segmentation (WSSS), such classifiers usually focus on discriminative object regions. In this paper, we propose Contrastive learning for Class-agnostic Activation Map (C$^2$AM) generation only using unlabeled image data, without the involvement of image-level supervision. The core idea comes from the observation that i) semantic information of foreground objects usually differs from their backgrounds; ii) foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space. We form the positive and negative pairs based on the above relations and force the network to disentangle foreground and background with a class-agnostic activation map using a novel contrastive loss. As the network is guided to discriminate cross-image foreground-background, the class-agnostic activation maps learned by our approach generate more complete object regions. We successfully extracted from C$^2$AM class-agnostic object bounding boxes for object localization and background cues to refine CAM generated by classification network for semantic segmentation. Extensive experiments on CUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and WSSS can benefit from the proposed C$^2$AM.


> [!tldr]- <center>éšè—ä¿¡æ¯</center>
> 
> itemType:: conferencePaper
> title:: Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation
> shortTitle:: 
> creators:: [[Jinheng Xie]]ã€ [[Jianfeng Xiang]]ã€ [[Junliang Chen]]ã€ [[Xianxu Hou]]ã€ [[Xiaodong Zhao]]ã€ [[Linlin Shen]]
> proceedingsTitle:: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
> conferenceName:: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
> place:: 
> publisher:: arXiv
> issue:: 
> pages:: 
> language:: 
> DOI:: [](https://doi.org/)
> ISBN:: 
> url:: [http://arxiv.org/abs/2203.13505](http://arxiv.org/abs/2203.13505)
> archive:: 2022-07-25
> archiveLocation:: 
> libraryCatalog:: 
> callNumber:: 
> rights:: 
> extra:: ğŸ·ï¸ _empahsisã€_readã€Computer Science - Computer Vision and Pattern Recognitionã€å¯¹æ¯”å­¦ä¹ 
> collection:: [[00_Histology]]
> tags:: #_empahsis #Done #å¯¹æ¯”å­¦ä¹  #Computer_Science_-_Computer_Vision_and_Pattern_Recognition
> related:: [[2020_Zhang_Rethinking the Route_KEY-BENL3W8J]]ã€ [[2019_Wei_Unsupervised object _KEY-C2TT9LJW]]
> itemLink:: [My Library](zotero://select/library/items/SXQ5HBNN)
> pdfLink:: [arXiv Fulltext PDF](zotero://open-pdf/library/items/VDK3A8LP)
> qnkey:: 2022_Xie_Contrastive learning_KEY-SXQ5HBNN
> date:: 2022-03-25
> dateY:: 2022
> dateAdded:: 2022-06-08
> dateModified:: 2022-07-26
> year:: 2022
> dateCurrent:: 2022-08-01
> time:: 10:34:17
> week:: æ˜ŸæœŸä¸€
> yearMonth:: 2022-08
> dateWeek:: 2022-08-01 æ˜ŸæœŸä¸€
> dateTime:: 2022-08-01 10:34:17
> dateWeekTime:: 2022-08-01 10:34:17 æ˜ŸæœŸä¸€
> 
> abstract:: While class activation map (CAM) generated by image classification network has been widely used for weakly supervised object localization (WSOL) and semantic segmentation (WSSS), such classifiers usually focus on discriminative object regions. In this paper, we propose Contrastive learning for Class-agnostic Activation Map (C$^2$AM) generation only using unlabeled image data, without the involvement of image-level supervision. The core idea comes from the observation that i) semantic information of foreground objects usually differs from their backgrounds; ii) foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space. We form the positive and negative pairs based on the above relations and force the network to disentangle foreground and background with a class-agnostic activation map using a novel contrastive loss. As the network is guided to discriminate cross-image foreground-background, the class-agnostic activation maps learned by our approach generate more complete object regions. We successfully extracted from C$^2$AM class-agnostic object bounding boxes for object localization and background cues to refine CAM generated by classification network for semantic segmentation. Extensive experiments on CUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and WSSS can benefit from the proposed C$^2$AM.


ğŸ‘£â¿ğŸ‘£


## âœï¸ ç¬”è®°åŒº

>[!inbox]- <center>ğŸ“« ç¬”è®°ç®€æŠ¥</center>
>
> â° importDate:: 2022-07-27

> [!IMPORTANT]+ <center>ğŸŒ± ç ”è¯»å°è±¡</center>  
>
>ğŸ“Œ comment::  

> [!WARNING]+ <center>ğŸ£ æ€»ç»“</center>  
>
>ğŸ¯ ç ”ç©¶é—®é¢˜::  
ğŸ” ç ”ç©¶èƒŒæ™¯::  
ğŸš€ ç ”ç©¶æ–¹æ³•::  
ğŸ” ç ”ç©¶æ€è·¯::  
ğŸ“º ä¸»è¦å†…å®¹::  
ğŸ‰ ç ”ç©¶ç»“è®º::  
ğŸ—ï¸ åˆ›æ–°ç‚¹::  
ğŸ’© ç ”ç©¶å±€é™::  
ğŸ¾ ç ”ç©¶å±•æœ›::  
âœï¸ å¤‡æ³¨::  


ğŸ‘£â¿ğŸ‘£

## ğŸ“ æ³¨é‡Šç¬”è®° VDK3A8LP

> <span style="font-size: 15px;color: gray">ğŸ“ 2022-Xie-Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation</span>

^KEYrefTitle

> <span class="highlight" style="background-color: #ffd40040">Contrastive learning for Class-agnostic Activation Map (C2AM)</span> ([p1](zotero://open-pdf/library/items/VDK3A8LP?page=1&annotation=MZ286SXN))

^KEYMZ286SXN

> <span class="highlight" style="background-color: #ffd40040">semantic information of foreground objects usually differs from their backgrounds</span> ([p1](zotero://open-pdf/library/items/VDK3A8LP?page=1&annotation=EIAU3L8P))

^KEYEIAU3L8P

> <span class="highlight" style="background-color: #ffd40040">foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space.</span> ([p1](zotero://open-pdf/library/items/VDK3A8LP?page=1&annotation=WDDE8ZBL))

^KEYWDDE8ZBL

> <span class="highlight" style="background-color: #ff666640">cross-image foreground-background contrast,</span> ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=UYPRKXVY))

^KEYUYPRKXVY

> <span class="image#ffd400">null</span>å»ºç«‹æ­£è´Ÿæ ·æœ¬å¯¹ï¼Œè¿™é‡Œæ˜¯é€šè¿‡ä¸€ä¸ªè§£ç¼ ç»•å™¨æ¥å°†feature mapåˆ†æˆnä¸ªå‰æ™¯å’Œnä¸ªèƒŒæ™¯ï¼Œç„¶åå»ºç«‹æ‰€æœ‰ç»„åˆçš„æ­£è´Ÿæ ·æœ¬å¯¹ã€‚ ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=WNEWH6GB))

^KEYWNEWH6GB

> <span class="highlight" style="background-color: #ff666640">The foreground-background representation pair, i.e., (vf i , vb j), is treated as the negative pair.</span> ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=2D4XTAEA))

^KEY2D4XTAEA

> <span class="highlight" style="background-color: #ffd40040">Positive pairs with large distances will affect the learning process, as there is fewer similar semantics in these two foreground objects or backgrounds.</span>  
> è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=P6QSBAAV))

^KEYP6QSBAAV

> <span class="image#ffd400">null</span>å»ºç«‹æ­£æ ·æœ¬å¯¹ã€‚å› ä¸ºåŒæ ·çš„æ ·æœ¬é—´æœ‰ç›¸ä¼¼çš„ç‰¹å¾ç©ºé—´ï¼Œå¦‚æœæ ·æœ¬é—´ç‰¹å¾ç©ºé—´çš„è·ç¦»è¾ƒè¿œè€Œå®ƒä»¬åˆå±äºåŒä¸€ç±»ï¼Œåˆ™ä¼šå¤§å¤§å½±å“è®­ç»ƒè¿‡ç¨‹ï¼Œæ‰€ä»¥éœ€è¦è¡¡é‡æ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»ï¼Œå¹¶ä¸”é€šè¿‡æ’åºçš„æ–¹æ³•æ¥èµ‹äºˆä¸åŒçš„æƒé‡ã€‚ ([p4](zotero://open-pdf/library/items/VDK3A8LP?page=4&annotation=7JXF7HJR))

^KEY7JXF7HJR

> <span class="highlight" style="background-color: #ffd40040">How to determine foreground regions. As th same contrastive loss is applied to foreground-foreground and background-background positive pairs, it can not guarantee that foreground or background regions are activated in Pi. To solve this problem, we set a threshold to binarize the class-agnostic activation maps and detect the largest contour to determine the object regions.</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=5HEEVM8Q))

^KEY5HEEVM8Q

> <span class="highlight" style="background-color: #ff666640">Specifically, WSOL is divided into two tasks: classagnostic object localization and object classification.</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=XNLTQDGC))

^KEYXNLTQDGC

> <span class="highlight" style="background-color: #ffd40040">We set a threshold to binarize the classagnostic activation maps and then extract class-agnostic object bounding boxes as pseudo labels</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=8NB5XJZD))

^KEY8NB5XJZD

> <span class="highlight" style="background-color: #ff666640">Specifically, we use the background activation maps (1âˆ’P) as pseudo labels to further train a model to predict the background regions, i.e., background cues, in the image.</span> ([p5](zotero://open-pdf/library/items/VDK3A8LP?page=5&annotation=CMIZAGBW))

^KEYCMIZAGBW







